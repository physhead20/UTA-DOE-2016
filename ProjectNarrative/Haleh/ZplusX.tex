\newcommand{\pt}{\mbox{$p_T$}}
%Although the SM has been extremely successful at explaining electroweak data, so-called problems with the theory, such as the quadratic divergence of radiative corrections to the Higgs mass (a.k.a. the Hierarchy problem), and unanswered questions, such as the nature of dark matter, drive our search for new phenomena at the TeV scale. We have strong arguments (i.e. naturalness and the ``dark-matter miracle'') 
%that solutions to these problems and questions may be found at this energy. 
%The leading theoretical solution is Supersymmetry (SUSY) since it not only addresses the hierarchy problem, but can also provide a dark matter candidate and predicts the unification of gauge couplings at the Grand Unified Theory (GUT) scale.
%We also know that the uncertainty of the current Higgs measurements allow for non-SM decays of the Higgs boson of 26\%~\cite{combin} and that theories with SM+singlets have equivalent level of branching fraction~\cite{exohiggs}.

The increased beam energy and intensity in the LHCâ€™s Run 2 and 3 will likely provide the best 
opportunity to discover BSM physics for at least the next ten years.
The task of discovering it, however, can be more challenging compared to the SM Higgs, whose mass was well constrained by precision electroweak data and the underlying theory, i.e. the SM, 
was well understood and extensively tested for over half a century~\cite{eng,higgs1,higgs2,higgs3}. 
In contrast, the number of theories and models that motivate BSM Higgs searches are significantly larger and more speculative, requiring that a much wider net be cast to cover a broader range of masses and final states. 

Hadavand proposes to perform searches using the 125 GeV Higgs to bootstrap her way to search for new exotic decays of the Higgs or other BSM states.  
The Higgs mass constraint will help aid the search for signal in a specific region.  %Or one can use the same final states and do a  more global search with no mass constraints by looking for Z+X final states where X $\rightarrow$ ll, including taus.
This method is motivated but not limited to the final states listed in table~\ref{tab:anal}. The search can be further expanded in a model-independent manner by scanning for Z+X where X can be of masses not theoretically motivated.
This proposal combines a search within five theoretical models each decaying to ll$\tau\tau$ and/or $\tau\tau$ll, thereby using our extensive experience with $\tau$ leptons.  With one analysis we are able to
cover all of these models thereby increasing the analysis reach.  

The Z+X search will primarily probe SUSY models for example Next-to-Minimal Supersymmetric Standard Model (NMSSM) that include an additional scalar singlet or SM +singlet models.  It can also be used to discover other states not theoretically motivated therefore investigating new mass regions where potential new particles could exist.
Additionally I propose searching for a ``dark'' Z in the mass range $12<$ m$<60$. A ``dark'' Z serves as the mediator of a new U(1) gauge symmetry that can serve as the portal to a hidden sector that constitutes dark matter~\cite{zdark}. 
Notice that in total there are five different theoretical models that decay into ll$\tau\tau$ and/or $\tau\tau$ll.  This is a great triumph over analyses that would at most cover a few final states.
Table ~\ref{tab:anal} summarizes all the channels and final states covered in the Z scan analysis.  Notice that each channel has the 125 GeV Higgs either in the initial or final state. 
Using the newly discovered Higgs particle in a broad scan will expand the experimental reach of this search.


\begin{table}[h]
\begin{center}
\begin{tabular}{ l |  l    |  l                   | l         || l    }  \hline 
 Analysis   & Channels        $\rightarrow$  &  $\tau \tau$ ll  & ll $\tau \tau$  &   Theory  \\ \hline \hline
\multirow{4}{*}{Z Scan} & $h\rightarrow ZZ^*$ &  $\checkmark$ & $\checkmark$                     & SM \\  

  &$A \rightarrow Zh$            &                    & $\checkmark$     &   MSSM, NMSSM \\  
  &$h \rightarrow$ ZZ(dark)  &    $ \checkmark$          & $\checkmark$  &dark U(1) gauge     \\   
  &$X(h) \rightarrow  Za$ for a l=$\mu$  &  $\checkmark$      & $\checkmark$ &   NSSM, SM+singlet\\ \hline \hline
%\multirow{2}{*}{$\mu$ Scan} & $h \rightarrow a a$  $l=\mu$ &    \checkmark            &\multicolumn{2}{c||}{$\checkmark$} & NSSM, SM+singlet\\
%  &$h \rightarrow$ Z(dark)Z(dark) & \checkmark &\multicolumn{2}{c||}{$\checkmark$}             & dark U(1) gauge\\\hline 
% & $H(G) \rightarrow hh$  & \multicolumn{3}{c||}{}  &   extra-dimensions , 2HDM\\  \hline

    \hline
    \end{tabular}
    \caption{ Table showing channels and accessible final states and theoretical models for several BSM models including the standard model h \too ZZ$^*$ channel~\cite{hexotic}.  The mass of the scalar singlet a and Z(dark) are  $4  <m(a)< 10 $GeV   $15 < m(Z(dark)) < 60 $GeV respectively.}
\label{tab:anal}
\end{center}
\end{table}

My strategy is to combine several final states and channels to increase statistics and look for a bump using a bump-hunting procedure I developed as a first pass. 
The approach removes the need for setting limits in a fine granularity in the discriminating variable, thereby greatly speeding up the statistical analysis. 
This speedup will allow for quicker turn around of searches in the absence of signal.  In the end the full statistical treatment as recommended for ATLAS will be performed to present the final 
results but this first pass will allow for flexibility in the search. 

For the Z mass scan I propose to perform two mass scans constraining the given particle combination to the Z mass and scanning in the 'other' particle. 
For example, Z(ll) other($\tau\tau$) and Z($\tau\tau$)other(ll) would be two separate scans of the 'other' particle after requiring that the event has a Z particle. 
The mass range of the scan would go from 4 GeV to 2 TeV and each object would be a resonance in that mass spectrum. The ee and $\mu\mu$ channels are added together 
in one spectrum since they have similar resolution and hence can increase the statistics for bump-hunting.  
The two scans, one with taus and the other with l=$\mu$,e  can then be combined together with a statistics framework.  
%leptons, reconstruct the mass and look in a range of 30 GeV to 2 TeV.  Similarly one can see from the channels in columns 3 and 4 (before the double lines) of the table that the same logic of scanning for the 'other particle' can be done over the same 
%region in mass. It is important to be able to combine the various physics models in one analysis since there are gaps in mass in the searches in the current Run 1 analysis.  These gaps need to be explored in our search for BSM
%phenomemon in Run 2 to make for a complete search.  
Of course the 4 lepton final state is one that is extensively tested for the SM ZZ* final state. This analysis would add the ll$\tau\tau$, $\tau\tau$ll final states to this channel for the first time.  The resolution will not be as favorable as
the 4 lepton final state but by constraining the on shell Z to decay to $\tau \tau$ one can improve the mass resolution.  These final states can add further sensitivity to this channel specially as the LHC
gathers more data.  With about 10 \invfb\ of data at the center of mass energy $\sqrt s$ = 13 TeV the 4 lepton analysis observed 3 events per category including a combination of electrons and muons.  The efficiency for tau reconstruction is lower (30-40\% as opposed to around 80\%) than the electron and muon channels and in 
addition pose a more challenging final state due to the existence of neutrinos.
However on average $35/80\times4\sim 2$ ($2\tau2e, 2\tau2\mu, 2e2\tau,2\mu2\tau$) events/10\invfb can be added to this channel~\cite{2016:4l} increasing the total statistics by 2/12=17\%. With a final dataset of 150\invfb of data this would be a significant addition to the existing channels.

%In the case that the sensitivity is not improved with this final state, this channel could be important for studying the missing ET in the diboson final states of the Higgs.
%It is entirely possible however that this final state will not improve the sensitivity in this channel but 
%In Run 1 several SM Higgs events had large associated missing ET and in one case a 4$\mu$ final state had MET of$\sim$ 100 GeV.  It would be interesting to see if more high MET events can be seen with the addition of the ll $\tau\tau$ statistics to this channel.

%A muon scan would be used to look for the channels h \too a a and Z(dark) Z(dark) final states. The lower predicated masses for these particles, $4  <m(a)< 10 GeV$  
%$15 < m(Z(dark)) < 60 GeV$, makes it natural to combine these two scans.  Granted that for h \too aa the $\mu\mu \tau \tau$ final state has the largest branching fraction and for the h \too Z(dark) Z(dark) the 4l final state has the 
%has the best resolution but in doing one analysis is it trivial to add the other final state and therefore increase statistics.  I would also not restrict this analysis to the mass range predicted for the a and Z(dark) particles but extend to masses of order 1 TeV.


%In building the analysis suite for \Hp $\tau \nu$ final state for high mass one needs to require at least two b jets and one tau in the final state.  At this point one can write out ntuples for the analysis and also allow for
%the option of adding an additional $\tau$ object to the final state. In this way one can have the $\tau\tau bb$ final state that can come from h \too aa or G(H)\too hh  within  the same framework. 
%I am sure there are many more overlaps that I am not covering in this proposal but this idea is presented here to make the point that overall discussions amongst physics groups are important before Run 2. People do no want to repeat the data redundancy and computing inefficiencies that happened during Run1.  Now it the time to take some action to prevent this for Run 2 by better organizing our analysis.  

By scanning for particles after selecting the Z boson one will get clear mass separation of the 'other' particle. The requirement of the Z boson in the event will also reduce backgrounds.  From Table~\ref{tab:anal} we see that many of the signals come from h, the 125 GeV Higgs.  If we were to look for the h mass we would get overlap between the various final states and it would be difficult to know which final
state actually contributed.  But by looking for the 'other' particle we can see the clear mass separation.  This method is also less restrictive on the analysis since one would not put any explicit selection on the mass
of the 'other' particle. In addition, another discriminating variable can be added to combine the Z and the 'other' particle and see if indeed one does reconstruct the hypothesized mass of the originating particle.  We can for example restrict the Z($\tau\tau$)other(ll) mass to be within the Higgs mass window to see if it will make the peaks in the other(ll) become clearer.  
%It is possible to perform a two-dimensional fit to both m(2obj) and m(4obj). 

%There is also a potential to use Dalitz plots for the three body final state h(A)\too Zll to separate various signal that would be overlapping.


%One can also do a two dimensional fit in the end to both m(2obj) and m(4obj). 


The SM ZZ* is the only channel that is not a resonance in the other(ll) spectrum.  It will have to be fit simultaneously as if it were a separate signal sitting on top of the Drell-Yan background.  Using the
bump-hunter to pick out this peak is not favorable since it is not a resonant peak and it can overlap with other signal.  By studying the shapes in MC and doing a parametric fit to the data one can determine the level of SM contribution to the mass spectrum.
In the end when reconstructing the 'other' mass one would see clear bumps for a, Z(dark), h in order of mass. The search can extend to high masses in case some other massive objects happens to appear in association with a Z boson.  

%The ZZ* channel will be handled differently such that the 'other' object, or the one for which the mass is reconstructed, will be the Z and the Z* will be the one reconstructed.  Since the Z* mass
%is not distinct resonance it makes sense to switch their place in the scan.

\subsubsection{Selection and Backgrounds to Z }
\label{sec:zscanback}
The selection for this analysis are still to be determined but would require a di-lepton pair if  $80<$m(ll)$<100$ GeV for the ee, and $\mu\mu$ channels and would require the use of the Missing Mass calculator for tau mass
reconstruction to determine the selection window around the Z mass.  In addition a medium/tight selection of the di-leptons will be made for the 'other' particle. 
When reconstructing the 'other' mass one can parameterize the fit to the background from a control region and extend it the entire range of the mass.  At low mass there will be resonant standard model particles which can be modeled with a combination of simulations and the use of the control regions.
The backgrounds include J$\psi$ ,$\Upsilon$, Z, \ttbar background, and Drell-Yan non-resonant background. In the intermediate mass there will be SM Z+h and ZZ* background as well.


%\subsubsection{$\mu$ Scan}
%For the aa and Z(dark)Z(dark) final state one can reconstruct one particle in both the ll and $\tau\tau$ final states and scan for the other in only the $\mu\mu$ final state.  In this way one can add statistics to these final and therefore be able to use the bump-hunter to look for potential signal.
%The 4e final state to Z(dark)Z(dark) will not be handled here for simplicity of looking only at the muon spectrum with the best statistics.

\paragraph{Determine Algorithm for Boosted/Collimated di-tau Pair Identification ; Postdoc} %(April 2017)
Since we are performing a general search where an unknown particle can decay to a Z boson and another potentially unknown particle, some events will have highly boosted and/`or highly collimated di-tau pairs that regular
tau reconstruction does not treat.  There has been work on ATLAS in this front aimed for reconstructing the channel A \too Z(ll) h($\tau\tau$)~\cite{di-tau-thesis}.  In this case the \pt of the di-tau system is quite high of an order of 500 GeV.
In other cases the \pt of the di-tau system can be small but they can be highly collimated.  This has been seen in the h \too a($\mu \mu$) a($\tau \tau$) analysis.  In fact the algorithm developed for A \too Z(ll) h($\tau\tau$) would not 
work for this channel because of the large \pt cut and the fact that it is seeded by a large R (1.0) Jet.  Large R jets only have calibration available for \pt larger than 200 GeV.  So I propose to develop a high \pt di-tau
algorithm and a low \pt highly collimated algorithm where standard jets of R of 0.4 can be used. A boosted decision tree (BDT) can be developed using the jet substructure information.  
The variables suggested to be used in the BDT or further studied within a Deep Neural Network are the following:
\begin{itemize}
\item{core energy fractions, $f_{core}^{sub(lead)}=\frac{\sum_{cells}^{\Delta R=0.1} p_{p,cell}}{\sum_{cells}^{\Delta R=0.2}p_{T,cell}} $}
\item {The subjet energy fractions $f(sub)lead_{subjet}=\frac{\pt^{subjet}}{\pt^{Jet}}$. }
\item{leading track momentum fractions $f(sub)lead_{subjet}=\frac{\pt ^{leadTrack}}{\pt^{subjet}}$}
\item{the maximum track distance Rmax}
\item{the number of tracks n(sub)leading track.}
\end{itemize}

\paragraph{Write General Analysis Suite for xAODs;  Postdoc, Akafzade} %(April 2017)
%The postdoc I will design and develop an analysis suite for the Z scan analysis.  
This analysis has leptons including taus in the final states so the analysis suite can be generalized but always adding a constraint of having a Z boson in the final state. 
 %The Z(dark)Z(dark) channel including four electrons will be left out of the analysis here due to the many channels already being explored.  This is to ensure
%symmetry between the h \too aa and Z(dark)Z(dark) making it easily combined in one analysis.  
Since we would like to perform an inclusive search of any particle decaying to Z+X we will keep this analysis suite very general. 
However, on top of the general analysis suite one can build tools to make additional requirements on the specific states. For example if there is mass constraint that can be imposed such as the mass of the Higgs.
%For example for the muon scan we can require that the two particle masses are within some limit of each other ie $\cbar$m(a$_1$)-m(a$_2$)\cbar$< \epsilon$ where $\epsilon$ will be governed by the detector resolution 
%of the different objects or just the natural width of the particle.  The resolution will matter for different pt objects or whether looking at the tau or muon final states.

\paragraph{Determine Background Parameterization from Control Regions, $\mu\mu$ scan ;  Postdoc, Akafzade, Hadavand}
Two control regions (CRs) are used in this analysis to constrain the SM backgrounds in the final fit to the data. The first region, CRj, is used to constrain the 
low mass SM resonances and Drell-Yan dominated non-resonant background. The second region, CRb, is used to constrain the \ttbar\ non-resonant background.
Both regions are defined by first requiring a tagged $\mu\mu$ candidate. CRj is further required to have
at least one selected jet and not be b-tagged. CRb is required to have at least two selected jets that have been b-tagged.
Any events which are in one of the SRs are excluded from the two CRs.

\paragraph{Determine Background Parameterization from Control Regions, $\tau\tau$ scan ;  Postdoc, Akafzade, Hadavand}
The control region used to determine the parametrization of the jets faking tau objects is defined as having two same sign tau leptons and inverting one of the tau identification criteria.
Simulation is used to predict the shape of the contribution from events with two true leptons and hadronically-decaying tau that are either correctly reconstructed or reconstructed
from leptons or leptonically-decaying taus.  These two parameterizations of the two backgrounds is then used to fit to the data as a more sophisticated template method.  The sidebands of the Z boson
can be used to validated this approach.

\paragraph{Parameterize Background ;  Akafzade, Hadavand} %(D - 3 months) 
As described in section~\ref{sec:zscanback} the backgrounds to the multiple BSM analysis  will be J/$\psi$, $\upsilon$, \ttbar, Drell-Yan, and Z tails.  One can 
parameterize these background from the control regions described above then fit for the normalization within the signal region similar to what is done in the
$\tau\tau \mu \mu$ analysis on ATLAS~\cite{tautaumumu}.  We also have the SM ZZ* as a non-peaking background which may be difficult to model. This background and the SM resonant backgrounds 
can be parameterized with MC and used in the fits. I have extensive experience with parameterized fits from the BABAR experiment and can guide my graduate student to model the various SM backgrounds.

\paragraph{Perform two separate scans in Z final state ;  Postdoc, Akafzade} %(D - 4 months)
In the decay of Y \too Z + X we call the mass of X can be reconstructed as X(ee), X($\mu\mu$), and X($\tau\tau$).  
The three Z scans look at the X(ee),X($\mu\mu$), and X($\tau\tau$) mass spectrum. For the X(ll), l=e,$\mu$ spectrum the Z will be reconstructed as Z($\tau\tau$).  For the X($\tau\tau$) spectrum the Z will be reconstructed in Z(ll), l=e,$\mu$.  
%By adding the various Z final states to the same spectrum we increase the statistics which will make it easier for the bump-hunter to determine if there is a signal.
The X(ee) and X($\mu\mu$) can be potentially combined if the resolution of the particles are similar enough.  The X($\tau\tau$) will not be combined with X(ll) l=e,mu since the resolution is quite different and the bump-hunter would not gain in looking for two overlapping bumps of vastly differing resolutions.
The use of the bump-hunter will allow for a first statistical pass at the data to determine if there is an existence of signal in the samples.  


%\paragraph{Muon Scan - aa and Z(dark)Z(dark) final state scan} (D - 4 months)
% The muon scan will look only at the m($\mu\mu$) and combine five final states in one mass spectrum.  The five final states include a($\mu\mu$)+$\Bigg(${a($\mu\mu$),a($\tau\tau$), Z(dark)($\mu\mu$), Z(dark)(ee), and Z(dark)($\tau\tau$)$\Bigg)$. The four electron final state will not be reconstructed for Z(dark)Z(dark) in this manner so to make the
% the analysis more simplified given the ambitious number of
% channels we aim to analyze in each scan.  The dilepton pair that are not scanned, 'other', will be reconstructed in m$_{\rm other}$(ll) l=e,$\mu$, $\tau$. The combination of these three channels will be combined to look at the dimuon mass spectrum.  A clear peak should appear in the presence of the narrow resonances
% of the scalar a and Z(dark).  My graduate student should be able to run the analysis suite and make these distributions.

%\paragraph{Determine other Discriminating Variables} (D - 4 months) 
%For the $\tau\tau$ final states an MMC calculator should be used for the Z scan analysis.  One can investigate the use of the Higgs mass to make peaks sharper.  For the $\mu$ scan can
%since the decay is to two identical particles can use an additional constraint on the mass in that way.  In doing so one much be careful in comparing masses of two taus to two leptons since the tau resolution will be a bit factor in the matching.  
%This is work that my graduate student can perform.

\paragraph{Develop and Optimize Bump-hunter to Scan Data ;  Hadavand, Akafzade} %(April '17)
I have previously worked on a bump-hunter which would be independent of the signal model used.  I called this program Signal Parameter Independent Fit (SPIF).  Using the parametrization described above we fit the data and remove a window where signal is expected.
The background is then extrapolated within this window and the difference of the number of events in the window versus the fit extrapolation is determined.  A p-value is determined using Poisson statistics for the difference between the number of events in the window and the extrapolated background within the window.
A scan is done using as input the step size and a of range of window sizes.  Several scans are performed changing the window size and step size iteratively until the p-value no longer improves within a specified precision.  
Once all iterations are performed, the window(s) with the smallest p-value(s) is(are) reported.  
%Using the bump-hunter can also work for blind analysis where only information about the significance of a  bump is presented but the total distribution can remain blind.
%Doing a bump-hunter scan can also save time in determining limits since putting limits on the entire distribution in very fine binning will take lots of CPU power.  
If the bump-hunter analysis reports no significant signal then a coarser binning can be used for the limit setting saving time and CPU power.



%\paragraph{Perform validation of bump-hunting technique ;  Akafzade} %(D - 2 months) 
%%To validate the performance of the bump-hunter in a specific environment one should test by injecting signal over the analytically determined background to see if the fit poses any biases and to test the sensitivity of the method in the presence of
%a specific type of signal as determined by various signal MC.  The iterative method used to hone in on the signal can be tested in to ensure no biases are present.

%\paragraph{Use tau handedness to Separate Z and Higgs decays} (now-Feb 2015)
%When performing the Z mass scan and it is determined that the SM h \too ZZ* is a large background to the A \too Z h final state we can perform a helicity cut to remove the Z* decays leaving in the scan only the resonant 
%decays.  This would only appear in the m($\tau\tau$) distribution where the Z would be reconstructed in the Z(ll) final states.  This will also make the work of the bump-hunter in this channel much easier since a broad shoulder 
%will be difficult to distinguish with a bump-hunter unless it is alternatively fitted out as a background.


%\paragraph{Optimize Binning for Limits } %(D - 2 months)
%Since in many cases we are looking in masses as high as a few TeV the background statistics will be limited in that region.  It is therefore important to perform binning optimization as it has been done 
%for the \Hp analysis to ensure the stability of the fit and to achieve the best possible limits in the absence of signal. The binning optimization is done by choosing different values of signal over background and total number of background to ensure the stability of the fits yet
%allow for the best possible limits.  This work can be done by myself and soon taken over by my graduate student.

\paragraph{Develop Limit setting software for various final states ;  Akafzade, Postdoc} %(D - 2 months)
%My extensive experience in developing limits setting software within the RooFit and RooStats framework will make this task somewhat simple to have my graduate student perform.  The most tedious part will be dealing systematics which will be in common across all the channels so time is saved in having 
%%originally harmonized analysis.  This is work that I can initiate with the help of Mr. Akafzade.
Once the background is parameterized and the normalization is determined from the signal region, we can determine limits using a binned maximum likelihood fit using  HistFactory as is usually done on ATLAS. 
For a search in a large window of mass typically a fine grid of masses are tested.  However with the input from the SPIF program we can only use a fine grid in regions where the p0 value is low indicating some deviation
from the background.  This will save CPU time in setting the final limits. 
Since our search includes several final states, these final states must be statically combined for each channel to get the best limits. 
%%
%\paragraph{Perform Model Dependent Exclusions ;  Postdoc} %(D - 1 months)
%With the use of the branching fractions for each model exclusions on various model parameters can be made using the cross section limits. For NMMSM or 2HDM the exclusions will be in the \tanb\ vs mA plane and \tanb\ vs $\cos(\beta-\alpha)$ plane.

