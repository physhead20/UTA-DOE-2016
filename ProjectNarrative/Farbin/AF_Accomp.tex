
\begin{center}
\Large\textbf{PI Summary: Amir Farbin}
\end{center}

The two drivers of my research are New Physics (NP) searches and
software and computing challenges. In the past three years, these
pursuits have kept me grounded in the LHC, where the frontiers of
these areas reside, while my focus was on the Intensity Frontier,
where I helped instantiate both the US's Long Baseline Neutrino and
UTA's neutrino programs. On September 1, 2016, my term as DUNE's
Deputy Software and Computing Coordinator (DS\&CC) ended. I chose to
not to ascend to full coordinator because it required a 100\%
commitment that would severe me from the LHC. Free of my Intensity
Frontier commitments and on sabbatical (Faculty Development Leave), I
have just changed my focus back to the ATLAS experiment and the 100\%
Energy Frontier program I outline in this proposal.

My ATLAS group, which now consists of postdoc Louise Heelan, and
recently graduated PhD student Daniel Bullock and new graduate student
Leslie Rogers, has a long history of leadership (twice as
subconveners) in the search for strongly produced squarks and
gluinos. These searches are where the LHC derives the most stringent
sparticle mass limits. We also brought the unconventional ``Razor''
technique to ATLAS in early Run 1 and followed through with four
iterations of searches, most recently in 13 TeV data for ICHEP 2016
using a generalization of the Razor~\cite{} technique called Recursive
Jigsaw~\cite{} to enhance sensitivity to compressed SUSY spectra
scenarios. My interest in this technique stems from its potential to
enable broader yet maximally sensitive searches, which will become
more relevant as data-doubling time for Run 2 analysis get
exponentially longer.  Section~\ref{} proposes a program that evolves
these techniques towards more sensitive and general searches as well
as targeting difficult regions, such as compressed SUSY spectra.

We also run the ATLAS software tutorials, a responsibility that I
picked up while serving as ATLAS's Physics Analysis Tools (PAT)
coordinator. This activity is project supported and will not be
covered in detail in this proposal due to space constraints, but
nonetheless is an important conduit to the latest developments in
ATLAS software. A decade ago, I participated in the installation,
commissioning, and operation of the Tile Hadronic Calorimeter
(TileCal). In recent years, my group has continued to contribute to
the study, operations, and upgrade of TileCal, through run
coordination, primary editing (i.e. writing) of the Tile performance
paper, and maintenance and upgrade of front-end electronics and mobile
test systems. My ATLAS roots are in that community. Heelan's roots are
in Calorimetry. Minimally, my students will continue to perform
service and qualify on TileCal.

My physics program in neutrinos, which will end with my student
Sepideh Shahsavarani's graduation in 2018, is also focused on NP
through searches for sub-GeV Dark Matter (DM) potentially produced in
the neutrino beamline. Using MiniBooNE's recent dedicated off-axis
run, Shahsavarani participates in the nearly complete DM-nucleon
scattering search while also leading the DM-electron scattering
search. She is simultaneously pursuing neutrino-Argon proton cross
section measurements in LArIAT. I just concluded serving as DUNE's
Deputy S\&C Coordinator, where I helped design and lead the computing
for the next generation of HEP experiments, bringing in experience
from the LHC, and building bridges between the Frontiers. Some of
these efforts will be described in section~\ref{}.

Recently, Deep Learning (DL) --an emerging branch of Machine Learning
which promises better and faster algorithms that are easier to develop
and scale, and enable new powerful workflows-- has grabbed my
interest, specifically with challenges of High Luminosity LHC (HL-LHC)
computing in mind. My efforts in this area has grown from a hobby to a
major thrust of research. I have been applying DL to a variety of HEP
problems in several different experiments via collaborations with
numerous HEP and DL colleagues. Early on, I was the first to
demonstrate DL image processing potential in LArTPC neutrino
experiments and Gas TPC neutrinoless double-beta decay experiments. I
have jump-started many HEP collaborators by providing software
support, GPUs, and producing large public data samples, while
personally tackling some of the most difficult problems in
collaboration with DL colleagues. Section~\ref{} overviews my
extensive program of DL projects and outlines how they naturally
extend to the LHC, for example in Calorimetry. Almost all of my and
fractions of other UTA PIs, will include a DL component. My
considerable lead in the application of DL to HEP has yielded numerous
workshop and conference presentations and organization roles in the
past year\cite{}, including the only DL talk at ICHEP 2016\cite{}.

%, as do and other UTA faculty's plans in both LArTPC,
%NEXT, and ATLAS BSM Higgs and Tau identification. 

The transition back to 100\% EF provides an opportunity for me to
pursue new software areas in ATLAS. For Run 3, ATLAS needs to migrate
to a Multi-threaded version of their Athena framework, where I have a
long history of contributions. Meanwhile ATLAS is woefully short of
software expertise and manpower. I propose to dedicate my focus in
ATLAS computing to aspects of this migration related specifically to
the Trigger and GPUs. While no further framework migration is planned
for Run 4, my now extensive experience with frameworks, Event Data
Model, GPUs, and co-processors lead me to believe that a new framework
is likely necessary and warranted.  I will play a leading role in
organizing the framework discussions in the community-wide white paper
orchestrated by Pete Elmer, Mike Sokoloff (U. Cincinnati), and Mark Neubauer in
preparation for a NSF SIS2 center proposal. Ideally we will organize a
workshop that will pull together framework experts across
experiments, many of whom I had the opportunity to closely work with
as DUNE DS\&CC. All of these activities will greatly benefit from my
proposed deep involvement in ATLAS Core Trigger software, where I
intend to assume critical responsibilities and leadership roles.

% I had the
%opportunity to throughly review art, LArSoft, and CMSWS frameworks,
%and set DUNE framework requirements and policy.
%
%throughly review art,
%LArSoft, and CMSWS frameworks, and set DUNE framework requirements and
%policy.



I find myself at the boundary of several distinct areas in HEP and HEP
Experiments. For a long time, I've straddled the fence between Physics
and Computing.  My strong computing skills and expertise have lead me
to assume roles generally assumed by computing oriented staff
scientists and engineers who often haven't touched real data for a
long time, and seldom tackled by professors, like me, with also close
connections to data analysis and detectors.  For the past three years,
I have had one foot in the Intensity Frontier and the other in the
Energy Frontier, developing a unique perspective of computing on both
fronts and establishing working relationships with many core
developers at Fermilab and CERN. Finally, my recent successes in the
DL have pushed me to boundaries of cutting edge Data Science and HEP,
yielding collaborations with new HEP experiments and Data
Scientists. There are boundaries in HEP that are rather difficult to
bridge. I believe that some of these boundaries can be resolved in
software and computing, ultimately yielding better science.

[The next three years look like this...]



